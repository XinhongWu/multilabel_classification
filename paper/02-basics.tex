\section{Grundlagen}
\subsection{Multilabel Klassifikation}
\label{sub:multilabel_klassifikation}
Es existieren zwei Arten von Ansätzen, um das Multilabel Klassifikation Problem zu lösen.
Bei der ersten wird das Problem transformiert und bei der zweiten werden existierende Verfahren adaptiert.
% comment lusy: verstehe ich nicht

\subsection{Support Vector Machines}
\label{sub:support_vector_machines}
Die \emph{Support Vector Machine} (SVM) ist ein Verfahren des überwachten Lernens, das zum Klassifizieren von Objekten verwendet wird.
Zum Lernen einer SVM werden die Trainingsdaten als Vektoren, zusammen mit den zugehörigen Klassen übergeben.
Für Texte ist die Repräsentation als Vektor meistens das Vektorspace-Modell, bei dem jedes Wort in dem Text als Feature angesehen wird.
Die SVM versucht dann anhand dieser Daten eine Hyperebene so in den Raum zu legen, so dass die Trainingsdaten in zwei Klassen eingeteilt werden.
Der Abstand der Vektoren, die der Hyperebene am nächsten liegen, wird dabei maximiert.
Ursprünglich wurden SVMs zur Unterteilung der Objekte in nur zwei Klassen konzipiert.
Es wurde gezeigt, dass Support Vector Machines eines der besten Verfahren zur Klassifikation sind \cite{Joachims:1998:TCS:645326.649721}.


%\begin{figure}[h]
    %\centering
    %\def\svgwitdth{0.75\columnwidth}
    %\input{figures/svm_intro.pdf_tex}
    %\caption{Hypereben einer SVM im 2-dimensionalen}
    %\label{fig:svm_intro}
    %\footnote*{http://commons.wikimedia.org/wiki/File:Svm\_intro.svg}
%\end{figure}



Um Support Vector Machines für das Multilabel Klassifizierungsproblem zu adaptieren, wird für jede Klasse $c \in L$ ein $\tilde c$ bestimmt, sodass für ein Dokument $D_i$ mit den Labels $L_i$ gilt:
\[
    \tilde c =
    \begin{cases}
        1 &\mbox{wenn } c \in L_i \\
        0 &\mbox{sonst}
    \end{cases}
\]

wobei $\tilde c$ die neue zu lernende Klasse für den binären Klassifkator repräsentiert.
Zur Klassifikation von neuen ungesehen Dokumenten wird nun jeder der binären Klassifikatoren gefragt, ob das aktuelle Dokument zu der gelernten Klasse gehört.
Ist die Antwort positiv, wird sich für dieses Dokument diese Klasse notiert, so dass man am Ende eine Menge von Klassen für das Dokument erhält.


\subsection{Latent Dirichlet Allocation}
\label{sub:latent_dirichlet_allocation}

Die \emph{Latent Dirichlet Allocation} (LDA) ist ein generatives stochastisches Modell, das eine Topic-Verteilung für eine angegebene Menge von Textdokumenten errechnet.
Dabei ist jedes Topic eine Verteilung über allen in der Dokumentensammlung vorhandenen Wörtern.
Jedes Dokument kann als eine Verteilung über Topics dargestellt werden.

% jedes Topic ist eine Verteilung über Wörter
% jedes Dokument ist Verteilung über Topics
% Latent Dirichlet Allocation(LDA)
%      generativer Prozess zum finden von Topics der Dokumente
%      findet k Topics auf Dokumenten



\subsection{Evaluierungsmaße}
Um die erzielten Ergebnisse auswerten und mit einander vergleichen zu können, haben wir die gängigen Maße \emph{Precision}, \emph{Recall} und \emph{F1} genutzt.
Vollständigkeitshalber werden hier nochmal die entsprechenden Gleichungen aufgeführt.

Precision \[\frac{\#(\text{relevant items retrieved})}{\#(\text{retrieved items})}\]
Recall \[\frac{\#(\text{relevant items retrieved})}{\#(\text{relevant items})}\]
F1-Measure \[F_1 = 2 \cdot \frac{\mathrm{precision} \cdot \mathrm{recall}}{\mathrm{precision} + \mathrm{recall}}\]

Ferner wurden zwei verschiedene Ansätze genutzt, um die Ergebnisse für ein Verfahren über alle Klassen zusammenzufassen.
Es wurden über alle Klassen sowohl die Micro- als auch die Macro-Precision, Recall und F1-Measure berechnet.
Die Macro-Average-Maße berechnen einen einfachen Durchschnitt über alle Klassen, während die Micro-Average-Maße die Klassen nach deren Größen gewichten \cite{Manning:2008:IIR:1394399}.

% TODO: micro/macro average F1-Measure --> nachdem P. die Ergebnisse korrigiert hat
%"Macroaveraging computes a simple average over classes.....
%The differences between the two methods can be large. Macroaveraging
%gives equal weight to each class, whereas microaveraging gives equal weight
%to each per-document classification decision."
