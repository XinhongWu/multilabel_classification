\section{Methoden}

%Datensatz
%Verwendete Tools
%Eigene Implementierung

\subsection{Datensatz}
\label{sub:datensatz}
%woher kommt der Datensatz?
Der untersuchte Datensatz besteht aus $1.1$ Millionen mathematischen Publikationen mit Titel, Abstract, Klassen und Erscheinungsjahr.
Der schematische Aufbau des Datensatzes wird in Tabelle \ref{tab:data} dargestellt.

%[Doc:] [ID] [LABELS] [YEAR] [TITLE] [ABSTRACT]
\begin{table}[h]
    %\rowcolors[]{1}{blue!20}{blue!10}
    \begin{tabular}{cccll}
        \tiny\textbf{ID} &\tiny \textbf{CLASSES} &\tiny \textbf{YEAR} &\tiny \textbf{TITLE} & \tiny \textbf{ABSTRACT} \\
        \hline
        \tiny 1000000796 &\tiny EW & \tiny 2000 & \tiny Dynamo: A transparent dynamic \dots  & \tiny We describe the design \dots \\
        \tiny 1000000815 &\tiny EW & \tiny 2000 & \tiny Unification-based pointer \dots  & \tiny This paper describes \dots \\
        \multicolumn{5}{c}{\dots} \\
        \tiny 1000003814 &\tiny EV,PE & \tiny 1995 & \tiny A GENETIC APPROACH TO \dots  & \tiny The quadratic assignment \dots \\
        \tiny 1000004333 & \tiny PQ,EX &\tiny 1995 &\tiny DYNAMIC EUCLIDEAN MINIMUM \dots & \tiny We maintain the minimum \dots \\
    \end{tabular}
    \caption{Auszug des Datensatzes}
    \label{tab:data}
\end{table}


Die Publikationen werden in 14 verschiedene Klassen eingeteilt.
Für $75.6 \%$ der Dokumente wurde nur eine Klasse vergeben, für $24.3 \%$ -- zwei Klassen und für $0.1 \%$ -- mehr als zwei Klassen.
Jedes Dokument wird mindestens einer Klasse zugeordnet.
Tabelle \ref{tab:class_meaning} gibt einen Überblick über die Häufigkeit und Bedeutung der im Datensatz verwendeten Klassenlabels.
%ist es nicht cooler die Häufigkeiten in % anzugeben? ich finds iwie übersichtlicher..



\begin{table}[h]
    \centering
    \begin{tabular}{l|l|l}
        \textbf{Klasse} & \textbf{Bedeutung} & \textbf{Häufigkeit}\\
        \hline
        AC & Automation \& Control Systems & 67450\\
        EV & Computer Science, Interdisciplinary Applications & 122025\\
        EW & Computer Science, Software Engineering & 70796\\
        EX & Computer Science, Theory \& Methods & 136456\\
        MC & Mathematical \& Computational Biology & 41590\\
        PE & Operations Research \& Management Science & 85476\\
        PN & Mathematics, Applied & 266198\\
        PO & Mathematics, Interdisciplinary Applications & 82404\\
        PQ & Mathematics & 255421\\
        PS & Social Sciences, Mathematical Methods & 25679\\
        QL & LOGIC & 1448\\
        UR & Physics, Mathematical & 149917\\
        VS & Psychology, Mathematical & 8439\\
        XY & Statistics \& Probability & 104227\\
    \end{tabular}
    \caption{Bedeutung und Häufigkeit der Klassen im Datensatz}
    \label{tab:class_meaning}
\end{table}


\subsection{Allgemeine Vorverarbeitung}

Zunächst haben wir unseren Datensatz in Test- und Trainingsdaten im Verhältnis 3:7 aufgeteilt, um unser gelerntes Modell auf ungesehen Daten testen zu können.
Für die Aufteilung wurde \emph{stratified sampling} verwendet, sodass die Klassen anteilig in Test- und Trainingsdaten vertreten sind.
Wichtig hierbei ist es, dass wir anstatt der einzelnen Klassen die vergebenen Klassenkombinationen verwenden, sodass die Kombinationen von Klassen anteilig in den beiden Datensätzen auftreten.

Ferner haben wir im Trainingdatensatz Stoppwörter wie ``the'', ``a'', ``at'', ``which'', etc. entfernt, da diese für eine Klassifizierung wenig Information liefern.
Hierfür haben wir .... benutzt. %tool

% noch was?

\subsection{Multilabel-Klassifikation}
% scikit-learn: LinearSVC

\subsection{Dimensionsreduktion mit LDA und Multilabel-Klassifikation}
% mallet für LDA
% scikit-learn: LinearSVC für die Klassifikation
% was ist überhaupt die Motivation für die Dimensionsreduktion?
    %Hoch-dimensionale Daten (> 1 Mio. Merkmale)
    % jedes Wort ist Feature
    %Sehr dünn besetzte (sparse) Vektoren
    % d.h. sehr wenige Informationen pro Merkmal
    % Reduktion auf wenige (100-1000?) Dimensionen (die Topics werden die Features für die SVM)
    % Kann auch als Kompression betrachtet werden.
    % Spart Rechenzeit, Speicher, ...
    % Erkennung und Clustering zusammenhängender Merkmale.
    %\frametitle{Vorbereitung Topic models}
    %\begin{itemize}
    %    \item Verteilung der Topics ist Feature für Dokumente
    %    \item Werte zwischen 0 und 1
    %    \item Summe für Einträge eines Dokuments beträgt 1
    %    \item Eintrag i enthält die Wahrscheinlichkeit für Topic i
    %    \item $\#topics << \#words$

