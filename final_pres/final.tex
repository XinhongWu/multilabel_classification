\documentclass[12pt, xcolor=table]{beamer}
\usepackage{graphicx}
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{fancyvrb}
\usepackage{color}
\usepackage{verbatim}

\usepackage[percent]{overpic}
\usepackage[footnotesize, bf]{caption}
\input{theme.tex}
\input{syntax}
\renewcommand{\footnotesize}{\tiny}

\begin{document}
\title{Endpräsentation - Multilabel Classification}
\author{peterr und Lusy}
\date{\today}

\begin{frame}
    \titlepage
    \begin{block}
        \tiny \url{https://github.com/lusy/multilabel\_classification}
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{Übersicht}
    \tableofcontents
\end{frame}

\begin{frame}
     \frametitle{Einleitung}
     \begin{itemize}
         \item Reduktion der Features durch Topic Models
         \item Multilabel problem, jeder Eintrag  kann in mehreren Klassen fallen
     \end{itemize}
\end{frame}

\section{Datensatz}
\begin{frame}
    \frametitle{Datensatz}
    \begin{itemize}
        \item mathematische Publikationen mit Titeln und Abstracts
        \item enthält  $1.1$ Mio. Dokumente
        \item jedes Dokument hat min. 1 Label
        \item $75.6 \%$ 1 Label, $24.3 \%$ 2 Label und ca. $0.1 \%$ mehr Labels
    %\item aus welchen Jahren sind die Publikationen
    \end{itemize}
    \begin{block}{Auszug}
        \begin{table}
            \rowcolors[]{1}{blue!20}{blue!10}
            \begin{tabular}{cccll}
                \tiny\textbf{ID} &\tiny \textbf{CLASSES} &\tiny \textbf{YEAR} &\tiny \textbf{TITLE} & \tiny \textbf{ABSTRACT} \\
                \hline
                \tiny 1000000796 &\tiny EW & \tiny 2000 & \tiny Dynamo: A transparent dynamic \dots  & \tiny We describe the design \dots \\
                \tiny 1000000815 &\tiny EW & \tiny 2000 & \tiny Unification-based pointer \dots  & \tiny This paper describes \dots \\
                \multicolumn{5}{c}{\dots} \\
                \tiny 1000003814 &\tiny EV,PE & \tiny 1995 & \tiny A GENETIC APPROACH TO \dots  & \tiny The quadratic assignment \dots \\
                \tiny 1000004333 & \tiny PQ,EX &\tiny 1995 &\tiny DYNAMIC EUCLIDEAN MINIMUM \dots & \tiny We maintain the minimum \dots \\
            \end{tabular}
             \caption*{Auszug des Datensatzes}
        \end{table}
    \end{block}
\end{frame}

\subsection{Idee} % (fold)
\begin{frame}
     \frametitle{Idee}
     \begin{itemize}
         \item jeder Eintrag hat mehrere Labels
         \item State-of-the-Art Textklassifikation mit SVM und Text im Vector-Space-Model
         \item Nachteil: sehr großer Featureraum - jedes Wort ist Feature
         \item Ansatz: Featurereduktion mit Topic Models
     \end{itemize}
\end{frame}

\section{Tools}
\begin{frame}
    \frametitle{Tools}
    \begin{itemize}
        \item Vorverabeitung: bash, python (+scipy, scikit-learn)
        \item SVM: scikit-learn (LinearSVC)
        \item LDA: mallet
    \end{itemize}
\end{frame}

\section{Vorbereitung SVM}
\begin{frame}
    \frametitle{Vorbereitung SVM}
    \begin{itemize}
        \item Darstellung der Texte im Vector-space-model
        \item entfernen von Stopwörtern(is, and, the, \ldots)
        \item Vokabular mit $n$ Wörtern: alle vorkommende Wörter in den Texten
    \end{itemize}
        \begin{table}
            \rowcolors[]{1}{blue!20}{blue!10}
            \begin{tabular}{c|cccc}
                \tiny\textbf{$doc_{id}$} &\tiny \textbf{$word_{1}$} &\tiny \textbf{$word_{2}$} &\tiny \textbf{\dots} & \tiny \textbf{$word_{n}$} \\
                \hline
                \tiny 1000000796 &\tiny 1 & \tiny 2 & \tiny  \dots  & \tiny 0 \\
                \tiny 1000000815 &\tiny 0 & \tiny 3 & \tiny \dots  & \tiny 1 \\
                \multicolumn{5}{c}{\dots} \\
                \tiny 1000003814 &\tiny 2  & \tiny 0 & \tiny  \dots  & \tiny 0 \\
                \tiny 1000004333 & \tiny 0 &\tiny 0 &\tiny  \dots & \tiny 1 \\
            \end{tabular}
             \caption*{Darstellung im Vektor space model}
        \end{table}
\end{frame}
\section{Topic Models mit LDA}
\begin{frame}
    \frametitle{Topic models mit LDA}
    \begin{center}
        \includegraphics[scale=0.35]{figures/IntroToLDA.png}
    \end{center}
    \footnotetext{LDA Model from Blei}
\end{frame}

\section{Vorbereitung Topic Models}
\begin{frame}
    \frametitle{Vorbereitung Topic models}
    \begin{itemize}
        \item Verteilung der Topics ist Feature für Dokumente
        \item Werte zwischen 0 und 1
        \item Summe für Einträge eines Dokuments beträgt 1
        \item Eintrag i enthält die Wahrscheinlichkeit für Topic i
        \item $\#topics << \#words$
    \end{itemize}
        \begin{table}
            \rowcolors[]{1}{blue!20}{blue!10}
            \begin{tabular}{c|cccc}
                \tiny\textbf{$doc_{id}$} &\tiny \textbf{$topic_{1}$} &\tiny \textbf{$topic_{2}$} &\tiny \textbf{\dots} & \tiny \textbf{$topic_{n}$} \\
                \hline
                \tiny 1000000796 &\tiny 0.1 & \tiny 0.05 & \tiny  \dots  & \tiny $1 \cdot 10^{-6}$  \\
                \tiny 1000000815 &\tiny 0.0 & \tiny 0.2 & \tiny \dots  & \tiny 0.1 \\
                \multicolumn{5}{c}{\dots} \\
                \tiny 1000003814 &\tiny 0.3  & \tiny $1 \cdot 10^{-6}$ & \tiny  \dots  & \tiny 0.0 \\
                \tiny 1000004333 & \tiny 0.0 &\tiny 0.0 &\tiny  \dots & \tiny 0.2 \\
            \end{tabular}
            \caption*{Repräsentation durch Topic Verteilung}
        \end{table}
\end{frame}
\end{frame}

\section{Sampling der Daten}
\begin{frame}
    \frametitle{Sampling der Daten}
    \begin{itemize}
        \item Stratified Sampling
        \item anhand der Labelkombinationen, also 'EW,PE' eine Klasse
        \item jedes Label kommt sowohl in Testdatensatz und Trainingsdatensatz vor
        \item Aufteilung: 70\% zum Trainieren und 30 \% zum Testen
    \end{itemize}
\end{frame}

\section{Ergebnisse der SVM}
\subsection{Labelkombinationen} % (fold)
\begin{frame}
    \frametitle{Labelkombinationen SVM}
    %\begin{center}
        %\includegraphics[scale=0.5]{figures/test.png}
    %\end{center}
\end{frame}

\subsection{Multilabel} % (fold)
\begin{frame}
    \frametitle{Multilabel SVM}
    %\begin{center}
        %\includegraphics[scale=0.5]{figures/test.png}
    %\end{center}
\end{frame}

\section{Ergebnisse mit Topic Models}
\begin{frame}
    \frametitle{Ergebnisse mit Topic Models}
    \begin{block}{Labelkombination}
        Mean F1-Score beträgt $5 \%$
    \end{block}
    \begin{block}{Jedes Label einzeln mit OvR}
        Mean F1-Score beträgt $3 \%$
    \end{block}
\end{frame}
%\subsection{Labelkombinationen} % (fold)
%\begin{frame}
     %\frametitle{Labelkombinationen}
%\end{frame}

%\subsection{Multilabel} % (fold)
%\begin{frame}
     %\frametitle{Multilabel}
%\end{frame}

\section{Ursachen und Probleme}
\begin{frame}
    \frametitle{Probleme}
    \begin{itemize}
        \item Wahrscheinlichkeiten der Topics sehr schnell sehr klein
        \item Vektoren sind voll besetzt im Gegensatz zu unigram-Modell
        \item großer Speicheraufwand
        \item Ansatz performt nicht auf ungesehen Daten
    \end{itemize}
\end{frame}

\section{Ausblick} % (fold)
\begin{frame}
    \frametitle{Ausblick}
    \begin{itemize}
        \item keinen
    \end{itemize}
    \begin{block}{Danke}
        Fragen?
    \end{block}
\end{frame}


\end{document}
